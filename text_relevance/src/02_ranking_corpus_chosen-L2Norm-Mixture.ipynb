{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import operator\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "\n",
    "from Normalizer import Normalizer\n",
    "\n",
    "from Parser import ParsedDocumentFormat, filter_text, normalize_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data2/\"\n",
    "folders = os.listdir(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs_parsed_paths = dict()\n",
    "\n",
    "for folder_i, folder_name in enumerate(folders):\n",
    "    path  = DATA_PATH + folder_name + '/'\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    for file_i, file_name in enumerate(files):\n",
    "        docs_parsed_paths[int(file_name)] = path + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId  DocumentId\n",
       "0        1         222\n",
       "1        1         244\n",
       "2        1         842\n",
       "3        1         851\n",
       "4        1        1226"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"../sample.csv\")\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = sample.groupby(\"QueryId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(\"../queries.numerate.fixed.txt\", mode=\"r\", encoding=\"utf-8\") as f_name:\n",
    "    queries = dict()\n",
    "    \n",
    "    for pair in f_name:\n",
    "        pair = pair.strip().split('\\t')\n",
    "        if len(pair) == 2:\n",
    "            pair[0] = int(pair[0])\n",
    "            pair[1] = normalize_text(normalizer, filter_text(pair[1])).strip().split()\n",
    "            queries[pair[0]] = pair[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_group_docs_parsed(group_docs):\n",
    "    group_docs = group_docs.DocumentId.values\n",
    "    group_docs_parsed = {\n",
    "        \"index\":       [],\n",
    "        \"title\":       [],\n",
    "        \"description\": [],\n",
    "        \"keywords\":    [],\n",
    "        \"text\":        []\n",
    "    }\n",
    "    \n",
    "    for doc in group_docs:\n",
    "        if doc not in docs_parsed_paths:\n",
    "            continue\n",
    "            \n",
    "        file_name = docs_parsed_paths[doc]\n",
    "        doc_parsed = ParsedDocumentFormat.load(file_name)\n",
    "        \n",
    "        for key in group_docs_parsed.keys():\n",
    "            group_docs_parsed[key].append(doc_parsed[key])\n",
    "    \n",
    "    return group_docs_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TfIdfRanker:\n",
    "    def __init__(self, key, norm='l2'):\n",
    "        stopwords = map(normalizer.get_normal_form, sw.words('russian'))\n",
    "        \n",
    "        self.vectorizer = TfidfVectorizer(stop_words=stopwords, max_features=int(10e6), norm=norm)\n",
    "        self.key = key\n",
    "        \n",
    "    def rank(self, query, docs):\n",
    "        group_docs_parsed = get_group_docs_parsed(docs)\n",
    "        \n",
    "        n_docs  = len(group_docs_parsed[\"index\"])\n",
    "        n_query = len(query)\n",
    "        scores = np.zeros(shape=(n_docs, n_query), dtype=float)\n",
    "        \n",
    "        matrix = self.vectorizer.fit_transform(group_docs_parsed[self.key])\n",
    "        features = {word: i for i, word in enumerate(self.vectorizer.get_feature_names())}\n",
    "        \n",
    "        for word_i, word in enumerate(query):\n",
    "            if word in features:\n",
    "                scores[:, word_i] = matrix[:, features[word]].toarray().reshape(-1)\n",
    "        \n",
    "        scores = scores.sum(axis=1)\n",
    "        \n",
    "        result = zip(group_docs_parsed[\"index\"], scores)\n",
    "        # result = sorted(result, key=operator.itemgetter(1), reverse=True)\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339 of 339 processed...\n"
     ]
    }
   ],
   "source": [
    "keys_set = [\"title\", \"description\", \"keywords\", \"text\"]\n",
    "\n",
    "scores_by_query = dict()\n",
    "\n",
    "for query_i, query in queries.iteritems():\n",
    "    scores = dict()\n",
    "    \n",
    "    for key in keys_set:        \n",
    "        ranker = TfIdfRanker(key=key, norm='l2')\n",
    "        \n",
    "        docs = sample.get_group(query_i)\n",
    "        score = ranker.rank(query, docs)\n",
    "        \n",
    "        for pair in score:\n",
    "            if pair[0] not in scores:\n",
    "                scores[pair[0]] = []\n",
    "            scores[pair[0]].append(pair[1])\n",
    "    \n",
    "    for doc_i, value in scores.items():\n",
    "        scores[doc_i] = np.asarray(value)\n",
    "    \n",
    "    scores_by_query[query_i] = scores\n",
    "        \n",
    "    print u\"\\r{} of {} processed...\".format(query_i, len(queries)),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('title', 1.0), ('description', 0.5), ('keywords', 0.5), ('text', 2.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray([1.0, 0.5, 0.5, 2.0], dtype=float)\n",
    "zip(keys_set, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def comparator(this, that):\n",
    "    result = int(this[0] - that[0])\n",
    "    if result:\n",
    "        return result\n",
    "    else:\n",
    "        result = -(this[2] - that[2])\n",
    "        if result > 0:\n",
    "            return 1\n",
    "        elif result < 0:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for query_i, query_sc in scores_by_query.iteritems():\n",
    "    score = [(query_i, doc_i, (values * weights).sum()) for doc_i, values in query_sc.iteritems()]\n",
    "    score = sorted(score, cmp=comparator)[:10]\n",
    "    scores.extend(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 20648, 3.4611142456980808),\n",
       " (1, 25164, 3.4295632755321606),\n",
       " (1, 1226, 3.4151675283374394),\n",
       " (1, 19604, 3.1302664656452683),\n",
       " (1, 11741, 3.1302664656452683),\n",
       " (1, 25371, 3.0254164703318556),\n",
       " (1, 4845, 2.901741603431546),\n",
       " (1, 25333, 2.8324324906201976),\n",
       " (1, 13383, 2.6463599454617732),\n",
       " (1, 10149, 2.5072547484048897),\n",
       " (2, 2119, 3.0651560901323482),\n",
       " (2, 26413, 1.7996953409982912),\n",
       " (2, 25053, 1.7834559258002294),\n",
       " (2, 3054, 1.6983526745729882),\n",
       " (2, 10661, 1.664023270708586),\n",
       " (2, 2108, 1.5870023404807927),\n",
       " (2, 17932, 1.3192257349092178),\n",
       " (2, 2687, 1.2708758338993302),\n",
       " (2, 25103, 1.1732057205823534),\n",
       " (2, 22724, 1.1513232664116273),\n",
       " (3, 12698, 2.5346664619548216),\n",
       " (3, 25358, 2.3709796459047814),\n",
       " (3, 450, 2.2058724116280581),\n",
       " (3, 449, 1.9257640383426646),\n",
       " (3, 23211, 1.1073697057490439),\n",
       " (3, 17655, 0.90511143656678761),\n",
       " (3, 22870, 0.7908204546575297),\n",
       " (3, 6979, 0.6523081458572586),\n",
       " (3, 11534, 0.64830709237987716),\n",
       " (3, 15589, 0.63131897139775672)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QueryId</th>\n",
       "      <th>DocumentId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>19604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QueryId  DocumentId\n",
       "0        1       20648\n",
       "1        1       25164\n",
       "2        1        1226\n",
       "3        1       19604\n",
       "4        1       11741"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = pd.DataFrame(data=scores, columns=[\"QueryId\", \"DocumentId\", \"score\"])\n",
    "answer = answer[answer.columns[:-1]]\n",
    "answer.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "answer.to_csv(\"../submission_7.csv\", sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
